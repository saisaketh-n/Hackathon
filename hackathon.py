# -*- coding: utf-8 -*-
"""HACKATHON(Sai_Saketh).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fJNuehtdObWvRVXHBNGnupauHj0n6zDO

Import the Libraries required
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
import matplotlib
import warnings
warnings.filterwarnings('ignore')

"""Load the Dataset"""

df=pd.read_csv("IPL_Data.csv")

"""Understand the given Data"""

df.head()    #head-->first five rows

df.tail()    #tail-->first five rows

df.shape    #shape-->rows,columns

df.columns    #columns in dataset

df.info()    #types of data for each column (int,float,object,....)

df.describe()    #describes the numerical data's mean,avg,std,...

"""NULL Values in each column"""

df.isnull().sum()

df['Type'].value_counts()    #count of number of players of each type

"""Exploratory Data Analysis :
use plots to understand the data
"""

sns.countplot('Type',data=df)    #plot showing the count of players of each type
plt.show()

"""Boxplot showing the numerical data through quartiles"""

sns.boxplot(x='Type',y='ValueinCR',data=df)
plt.show()

sns.boxplot(x='Type',y='BattingAVG',data=df)
plt.show()

sns.boxplot(x='Type',y='BattingS/R',data=df)
plt.show()

sns.boxplot(x='Type',y='BowlingAVG',data=df)
plt.show()

sns.boxplot(x='Type',y='EconomyRate',data=df)
plt.show()

"""Correlation used to find relationship between columns"""

df.corr()

plt.subplots(figsize=(17,8))
sns.heatmap(df.corr())
plt.show()

"""Consider only required columns"""

x=df[['BattingAVG','BattingS/R','BowlingAVG','EconomyRate']]
y=df[['ValueinCR']]

plt.subplots(figsize=(10,5))
sns.heatmap(x.corr())
plt.show()

x.isna().sum()    #NULL values in each column

x.describe()

"""Replace NULL values of a column with the mean value of the column"""

x['BattingAVG'].fillna(17.988207	,inplace=True)
x['BattingS/R'].fillna(102.443765,inplace=True)
x['BowlingAVG'].fillna(34.496476,inplace=True)
x['EconomyRate'].fillna(8.656393,inplace=True)

x.isna().sum()    #NO NULL values

"""Preprocessing using sklearn"""

from sklearn.preprocessing import MinMaxScaler
m=MinMaxScaler()
df_sc=m.fit_transform(x)
df_sc_df=pd.DataFrame(df_sc,columns=x.columns,index=df.index)
x=df_sc_df

"""select train_test_split model for spliting data into 80% for training and 20% for testing"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

"""Floor or Ceil the values of the column "ValueinCR" to be non-continuous"""

for i in range(237):
  y_train['ValueinCR']=np.ceil(y_train['ValueinCR'])
  y_test['ValueinCR']=np.ceil(y_test['ValueinCR'])

y_train=y_train.astype(int)
y_test=y_test.astype(int)

from sklearn.metrics import accuracy_score

"""Use Lists for storing accuracy of train and test for different models"""

index=[]
models_test=[]
models_train=[]

from sklearn.ensemble import AdaBoostClassifier
adc=AdaBoostClassifier()
adc.fit(x_train,y_train)
pred_train=adc.predict(x_train)
mtrain=accuracy_score(y_train,pred_train)*100
print(mtrain)
pred_test=adc.predict(x_test)
mtest=accuracy_score(y_test,pred_test)*100
print(mtest)
index.append("AdaBoostClassifier")
models_train.append(mtrain)
models_test.append(mtest)

from sklearn.linear_model import LinearRegression
lr=LinearRegression()
lr.fit(x_train,y_train)
pred_train=lr.predict(x_train)
print(lr.score(x_test,y_test)*100)
index.append("LinearRegression")
models_train.append(lr.score(x_test,y_test)*100)
models_test.append(lr.score(x_test,y_test)*100)

from sklearn.ensemble import RandomForestRegressor
rf=RandomForestRegressor(n_estimators=100,random_state=42,max_depth=5,n_jobs=-1,oob_score=True)
rf.fit(x_train,y_train)
print(rf.oob_score_*100)
index.append("RandomForestRegressor")
models_train.append(rf.oob_score_*100)
models_test.append(rf.oob_score_*100)

from sklearn.naive_bayes import GaussianNB
gn=GaussianNB()
gn.fit(x_train,y_train)
pred_train=gn.predict(x_train)
mtrain=accuracy_score(y_train,pred_train)*100
print(mtrain)
pred_test=gn.predict(x_test)
mtest=accuracy_score(y_test,pred_test)*100
print(mtest)
index.append("GaussianNB")
models_train.append(mtrain)
models_test.append(mtest)

from sklearn.tree import DecisionTreeClassifier
dtc=DecisionTreeClassifier()
dtc.fit(x_train,y_train)
pred_train=dtc.predict(x_train)
mtrain=accuracy_score(y_train,pred_train)*100
print(mtrain)
pred_test=dtc.predict(x_test)
mtest=accuracy_score(y_test,pred_test)*100
print(mtest)
index.append("DecisionTreeClassifier")
models_train.append(mtrain)
models_test.append(mtest)

from sklearn.ensemble import ExtraTreesClassifier
etc=ExtraTreesClassifier()
etc.fit(x_train,y_train)
pred_train=etc.predict(x_train)
mtrain=accuracy_score(y_train,pred_train)*100
print(mtrain)
pred_test=etc.predict(x_test)
mtest=accuracy_score(y_test,pred_test)*100
print(mtest)
index.append("ExtraTreesClassifier")
models_train.append(mtrain)
models_test.append(mtest)

from sklearn.ensemble import GradientBoostingClassifier
gbc=GradientBoostingClassifier()
gbc.fit(x_train,y_train)
pred_train=gbc.predict(x_train)
mtrain=accuracy_score(y_train,pred_train)*100
print(mtrain)
pred_test=gbc.predict(x_test)
mtest=accuracy_score(y_test,pred_test)*100
print(mtest)
index.append("GradientBoostingClassifier")
models_train.append(mtrain)
models_test.append(mtest)

from sklearn.svm import SVC
svc=SVC()
svc.fit(x_train,y_train)
pred_train=svc.predict(x_train)
mtrain=accuracy_score(y_train,pred_train)*100
print(mtrain)
pred_test=svc.predict(x_test)
mtest=accuracy_score(y_test,pred_test)*100
print(mtest)
index.append("SVC")
models_train.append(mtrain)
models_test.append(mtest)

from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(x_train,y_train)
pred_train=lr.predict(x_train)
mtrain=accuracy_score(y_train,pred_train)*100
print(mtrain)
pred_test=lr.predict(x_test)
mtest=accuracy_score(y_test,pred_test)*100
print(mtest)
index.append("LogisticRegression")
models_train.append(mtrain)
models_test.append(mtest)

from sklearn.naive_bayes import BernoulliNB
bn=BernoulliNB()
bn.fit(x_train,y_train)
pred_train=bn.predict(x_train)
mtrain=accuracy_score(y_train,pred_train)*100
print(mtrain)
pred_test=bn.predict(x_test)
mtest=accuracy_score(y_test,pred_test)*100
print(mtest)
index.append("BernoulliNB")
models_train.append(mtrain)
models_test.append(mtest)

from sklearn.neighbors import KNeighborsClassifier
kn=KNeighborsClassifier(n_neighbors=8)
kn.fit(x_train,y_train)
pred_train=kn.predict(x_train)
mtrain=accuracy_score(y_train,pred_train)*100
print(mtrain)
pred_test=kn.predict(x_test)
mtest=accuracy_score(y_test,pred_test)*100
print(mtest)
index.append("KNeighborsClassifier")
models_train.append(mtrain)
models_test.append(mtest)

import xgboost as xg
from sklearn.metrics import r2_score
xgb_r=xg.XGBRegressor(n_estimators=503,eta=0.12,max_depth=7,subsample=0.1,colsample_bytree=1,colsample_bylevel=1,alpha=0.7,num_parallel_tree=8)
xgb_r.fit(x_train,y_train)
ypred=xgb_r.predict(x_test)
print(r2_score(y_test,ypred)*100)
index.append("xgboost")
models_train.append(r2_score(y_test,ypred)*100)
models_test.append(r2_score(y_test,ypred)*100)

"""Create a DataFrame to display accuracy of ML Algorithms in tabular format"""

df=pd.DataFrame(columns=["ML Algorithms","Train Accuracy","Test Accuracy"])
for i in range(len(models_train)):
  df.loc[i,"ML Algorithms"]=index[i]
  df.loc[i,"Train Accuracy"]=round(models_train[i],2)
  df.loc[i,"Test Accuracy"]=round(models_test[i],2)

df    #print the data

"""Plot the graphs to understand the training and testing accuracy of different ML Algorithm and find an algorithm best suits for given data"""

plt.subplots(figsize=(13,5))
sns.barplot(x="ML Algorithms", y="Train Accuracy",data=df)
plt.xticks(rotation=90)
plt.title('MLA Train Accuracy Comparison')
plt.show()

plt.subplots(figsize=(13,5))
sns.barplot(x="ML Algorithms", y="Test Accuracy",data=df)
plt.xticks(rotation=90)
plt.title('MLA Test Accuracy Comparison')
plt.show()

